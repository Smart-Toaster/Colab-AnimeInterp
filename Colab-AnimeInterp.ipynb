{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-AnimeInterp.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQy61byYFdKX"
      },
      "source": [
        "# Colab-AnimeInterp\n",
        "\n",
        "Original-repo: [lisiyao21/AnimeInterp](https://github.com/lisiyao21/AnimeInterp)\n",
        "\n",
        "My fork: [styler00dollar/Colab-AnimeInterp](https://github.com/styler00dollar/Colab-AnimeInterp)\n",
        "\n",
        "Don't use cpu, unless you are fine with like 75 seconds per image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHoHhFVk1CeU"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Zx0BZZP2GL9w"
      },
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMaEc9CJzxly",
        "cellView": "form"
      },
      "source": [
        "#@title install\n",
        "%cd /content/\n",
        "!git clone https://github.com/lisiyao21/AnimeInterp\n",
        "!wget \"https://www.dropbox.com/s/oc8juclx1775qib/anime_interp_full.ckpt?dl=1\" -O /content/anime_interp_full.ckpt\n",
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-myM_sWYM9dU"
      },
      "source": [
        "#@title get video / copy it into the cainapp folder\n",
        "%cd /content\n",
        "# either copy video from drive \n",
        "#!cp /path/ /path/\n",
        "\n",
        "#or get one with wget / youtube-dl\n",
        "# wget\n",
        "#!wget URL\n",
        "\n",
        "# youtube-dl\n",
        "!sudo rm -rf test.mp4\n",
        "!wget -O - https://yt-dl.org/latest/youtube-dl | sudo tee /usr/local/bin/youtube-dl > /dev/null\n",
        "!sudo chmod a+x /usr/local/bin/youtube-dl\n",
        "video_path = \"/content/test.mp4\"\n",
        "!youtube-dl \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" --output {video_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQjRM6mH2I0R"
      },
      "source": [
        "# extract data\n",
        "# adjust rescale value if needed, or remove it\n",
        "!mkdir /content/data\n",
        "input_path = \"/content/test.mkv\" #@param\n",
        "%shell ffmpeg -i {input_path} -vf scale=848:480:flags=lanczos \"/content/data/%05d.png\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ELl71MJwW-u"
      },
      "source": [
        "``cupy`` is much faster, I don't recommend without ``cupy``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBgqSnWZPjxX",
        "cellView": "form"
      },
      "source": [
        "#@title init.py (adding imports)\n",
        "%%writefile /content/AnimeInterp/models/__init__.py\n",
        "#from .AnimeInterp import AnimeInterp\n",
        "from .AnimeInterp_no_cupy import AnimeInterpNoCupy\n",
        "from .AnimeInterp import AnimeInterp\n",
        "\n",
        "__all__ = [ 'AnimeInterpNoCupy', 'AnimeInterp' ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIvtb7I1z3lL",
        "cellView": "form"
      },
      "source": [
        "#@title utils.py (F.grid_sample fix)\n",
        "%%writefile /content/AnimeInterp/models/rfr_model/utils.py\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "\n",
        "\n",
        "class InputPadder:\n",
        "    \"\"\" Pads images such that dimensions are divisible by 8 \"\"\"\n",
        "    def __init__(self, dims):\n",
        "        self.ht, self.wd = dims[-2:]\n",
        "        pad_ht = (((self.ht // 8) + 1) * 8 - self.ht) % 8\n",
        "        pad_wd = (((self.wd // 8) + 1) * 8 - self.wd) % 8\n",
        "        self._pad = [pad_wd//2, pad_wd - pad_wd//2, 0, pad_ht]\n",
        "\n",
        "    def pad(self, *inputs):\n",
        "        return [F.pad(x, self._pad, mode='replicate') for x in inputs]\n",
        "\n",
        "    def unpad(self,x):\n",
        "        ht, wd = x.shape[-2:]\n",
        "        c = [self._pad[2], ht-self._pad[3], self._pad[0], wd-self._pad[1]]\n",
        "        return x[..., c[0]:c[1], c[2]:c[3]]\n",
        "\n",
        "def forward_interpolate(flow):\n",
        "    flow = flow.detach().cpu().numpy()\n",
        "    dx, dy = flow[0], flow[1]\n",
        "\n",
        "    ht, wd = dx.shape\n",
        "    x0, y0 = np.meshgrid(np.arange(wd), np.arange(ht))\n",
        "\n",
        "    x1 = x0 + dx\n",
        "    y1 = y0 + dy\n",
        "    \n",
        "    x1 = x1.reshape(-1)\n",
        "    y1 = y1.reshape(-1)\n",
        "    dx = dx.reshape(-1)\n",
        "    dy = dy.reshape(-1)\n",
        "\n",
        "    valid = (x1 > 0) & (x1 < wd) & (y1 > 0) & (y1 < ht)\n",
        "    x1 = x1[valid]\n",
        "    y1 = y1[valid]\n",
        "    dx = dx[valid]\n",
        "    dy = dy[valid]\n",
        "\n",
        "    flow_x = interpolate.griddata(\n",
        "        (x1, y1), dx, (x0, y0), method='cubic', fill_value=0)\n",
        "\n",
        "    flow_y = interpolate.griddata(\n",
        "        (x1, y1), dy, (x0, y0), method='cubic', fill_value=0)\n",
        "\n",
        "    flow = np.stack([flow_x, flow_y], axis=0)\n",
        "    return torch.from_numpy(flow).float()\n",
        "\n",
        "\n",
        "def bilinear_sampler(img, coords, mode='bilinear', mask=False):\n",
        "    \"\"\" Wrapper for grid_sample, uses pixel coordinates \"\"\"\n",
        "    H, W = img.shape[-2:]\n",
        "    xgrid, ygrid = coords.split([1,1], dim=-1)\n",
        "    xgrid = 2*xgrid/(W-1) - 1\n",
        "    ygrid = 2*ygrid/(H-1) - 1\n",
        "\n",
        "    grid = torch.cat([xgrid, ygrid], dim=-1)\n",
        "    img = F.grid_sample(img, grid, align_corners=True, mode=\"bilinear\")\n",
        "    if mask==True:\n",
        "      mask = (xgrid > -1) & (ygrid > -1) & (xgrid < 1) & (ygrid < 1)\n",
        "      return img, mask.float()\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "def coords_grid(batch, ht, wd):\n",
        "    coords = torch.meshgrid(torch.arange(ht), torch.arange(wd))\n",
        "    coords = torch.stack(coords[::-1], dim=0).float()\n",
        "    return coords[None].repeat(batch, 1, 1, 1)\n",
        "\n",
        "\n",
        "def upflow8(flow, mode='bilinear'):\n",
        "    new_size = (8 * flow.shape[2], 8 * flow.shape[3])\n",
        "    return  8 * F.interpolate(flow, size=new_size, mode=mode, align_corners=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "eovj-oFp5_fE"
      },
      "source": [
        "#@title rfr_new.py (F.grid_sample fix)\n",
        "%%writefile /content/AnimeInterp/models/rfr_model/rfr_new.py\n",
        "##################################################\n",
        "#  RFR is implemented based on RAFT optical flow #\n",
        "##################################################\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from .update import BasicUpdateBlock, SmallUpdateBlock\n",
        "from .extractor import BasicEncoder, SmallEncoder\n",
        "from .corr import CorrBlock\n",
        "from .utils import bilinear_sampler, coords_grid, upflow8\n",
        "\n",
        "try:\n",
        "    autocast = torch.cuda.amp.autocast\n",
        "except:\n",
        "    # dummy autocast for PyTorch < 1.6\n",
        "    class autocast:\n",
        "        def __init__(self, enabled):\n",
        "            pass\n",
        "        def __enter__(self):\n",
        "            pass\n",
        "        def __exit__(self, *args):\n",
        "            pass\n",
        "\n",
        "def backwarp(img, flow):\n",
        "    _, _, H, W = img.size()\n",
        "\n",
        "    u = flow[:, 0, :, :]\n",
        "    v = flow[:, 1, :, :]\n",
        "\n",
        "    gridX, gridY = np.meshgrid(np.arange(W), np.arange(H))\n",
        "\n",
        "    gridX = torch.tensor(gridX, requires_grad=False,).cuda()\n",
        "    gridY = torch.tensor(gridY, requires_grad=False,).cuda()\n",
        "    x = gridX.unsqueeze(0).expand_as(u).float() + u\n",
        "    y = gridY.unsqueeze(0).expand_as(v).float() + v\n",
        "    # range -1 to 1\n",
        "    x = 2*(x/(W-1) - 0.5)\n",
        "    y = 2*(y/(H-1) - 0.5)\n",
        "    # stacking X and Y\n",
        "    grid = torch.stack((x,y), dim=3)\n",
        "    # Sample pixels using bilinear interpolation.\n",
        "    imgOut = torch.nn.functional.grid_sample(img, grid, align_corners=True, mode=\"bilinear\")\n",
        "\n",
        "    return imgOut\n",
        "class ErrorAttention(nn.Module):\n",
        "    \"\"\"A three-layer network for predicting mask\"\"\"\n",
        "    def __init__(self, input, output):\n",
        "        super(ErrorAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input, 32, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(38, output, 3, padding=1)\n",
        "        self.prelu1 = nn.PReLU()\n",
        "        self.prelu2 = nn.PReLU()\n",
        "\n",
        "    def forward(self, x1):\n",
        "        x = self.prelu1(self.conv1(x1))\n",
        "        x = self.prelu2(torch.cat([self.conv2(x), x1], dim=1)) \n",
        "        x = self.conv3(x)\n",
        "        return x\n",
        "\n",
        "class RFR(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(RFR, self).__init__()\n",
        "        self.attention2 = ErrorAttention(6, 1)\n",
        "        self.hidden_dim = hdim = 128\n",
        "        self.context_dim = cdim = 128\n",
        "        args.corr_levels = 4\n",
        "        args.corr_radius = 4\n",
        "        args.dropout = 0\n",
        "        self.args = args\n",
        "\n",
        "        # feature network, context network, and update block\n",
        "        self.fnet = BasicEncoder(output_dim=256, norm_fn='none', dropout=args.dropout)        \n",
        "        # self.cnet = BasicEncoder(output_dim=hdim+cdim, norm_fn='none', dropout=args.dropout)\n",
        "        self.update_block = BasicUpdateBlock(self.args, hidden_dim=hdim)\n",
        "        \n",
        "        \n",
        "\n",
        "    def freeze_bn(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "\n",
        "    def initialize_flow(self, img):\n",
        "        \"\"\" Flow is represented as difference between two coordinate grids flow = coords1 - coords0\"\"\"\n",
        "        N, C, H, W = img.shape\n",
        "        coords0 = coords_grid(N, H//8, W//8).to(img.device)\n",
        "        coords1 = coords_grid(N, H//8, W//8).to(img.device)\n",
        "\n",
        "        # optical flow computed as difference: flow = coords1 - coords0\n",
        "        return coords0, coords1\n",
        "\n",
        "    def upsample_flow(self, flow, mask):\n",
        "        \"\"\" Upsample flow field [H/8, W/8, 2] -> [H, W, 2] using convex combination \"\"\"\n",
        "        N, _, H, W = flow.shape\n",
        "        mask = mask.view(N, 1, 9, 8, 8, H, W)\n",
        "        mask = torch.softmax(mask, dim=2)\n",
        "\n",
        "        up_flow = F.unfold(8 * flow, [3,3], padding=1)\n",
        "        up_flow = up_flow.view(N, 2, 9, 1, 1, H, W)\n",
        "\n",
        "        up_flow = torch.sum(mask * up_flow, dim=2)\n",
        "        up_flow = up_flow.permute(0, 1, 4, 2, 5, 3)\n",
        "        return up_flow.reshape(N, 2, 8*H, 8*W)\n",
        "\n",
        "    def forward(self, image1, image2, iters=12, flow_init=None, upsample=True, test_mode=False):\n",
        "        H, W = image1.size()[2:4]\n",
        "        H8 = H // 8 * 8\n",
        "        W8 = W // 8 * 8\n",
        "\n",
        "        if flow_init is not None:\n",
        "            flow_init_resize = F.interpolate(flow_init, size=(H8//8, W8//8), mode='nearest')\n",
        "\n",
        "            flow_init_resize[:, :1] = flow_init_resize[:, :1].clone() * (W8 // 8 *1.0) / flow_init.size()[3]\n",
        "            flow_init_resize[:, 1:] = flow_init_resize[:, 1:].clone() * (H8 // 8*1.0) / flow_init.size()[2]\n",
        "            \n",
        "            if not hasattr(self.args, 'not_use_rfr_mask') or ( hasattr(self.args, 'not_use_rfr_mask') and (not self.args.not_use_rfr_mask)):\n",
        "                im18 = F.interpolate(image1, size=(H8//8, W8//8), mode='bilinear')\n",
        "                im28 = F.interpolate(image2, size=(H8//8, W8//8), mode='bilinear')\n",
        "                \n",
        "                warp21 = backwarp(im28, flow_init_resize)\n",
        "                error21 = torch.sum(torch.abs(warp21 - im18), dim=1, keepdim=True)\n",
        "                # print('errormin', error21.min(), error21.max())\n",
        "                f12init = torch.exp(- self.attention2(torch.cat([im18, error21, flow_init_resize], dim=1)) ** 2) * flow_init_resize\n",
        "        else:\n",
        "            flow_init_resize = None\n",
        "            flow_init = torch.zeros(image1.size()[0], 2, image1.size()[2]//8, image1.size()[3]//8).cuda()\n",
        "            error21 = torch.zeros(image1.size()[0], 1, image1.size()[2]//8, image1.size()[3]//8).cuda()\n",
        "\n",
        "            f12_init = flow_init\n",
        "            # print('None inital flow!')\n",
        "        \n",
        "        image1 = F.interpolate(image1, size=(H8, W8), mode='bilinear')\n",
        "        image2 = F.interpolate(image2, size=(H8, W8), mode='bilinear')\n",
        "\n",
        "        f12s, f12, f12_init = self.forward_pred(image1, image2, iters, flow_init_resize, upsample, test_mode)\n",
        "        \n",
        " \n",
        "        if (hasattr(self.args, 'requires_sq_flow') and self.args.requires_sq_flow):\n",
        "            for ii in range(len(f12s)):\n",
        "                f12s[ii] = F.interpolate(f12s[ii], size=(H, W), mode='bilinear')\n",
        "                f12s[ii][:, :1] = f12s[ii][:, :1].clone() / (1.0*W8) * W\n",
        "                f12s[ii][:, 1:] = f12s[ii][:, 1:].clone() / (1.0*H8) * H\n",
        "            if self.training:\n",
        "                return f12s\n",
        "            else:\n",
        "                return [f12s[-1]], f12_init\n",
        "        else:\n",
        "            f12[:, :1] = f12[:, :1].clone() / (1.0*W8) * W\n",
        "            f12[:, 1:] = f12[:, 1:].clone() / (1.0*H8) * H\n",
        "\n",
        "            f12 = F.interpolate(f12, size=(H, W), mode='bilinear')\n",
        "            # print('wo!!')\n",
        "            return f12, f12_init, error21, \n",
        "            \n",
        "    def forward_pred(self, image1, image2, iters=12, flow_init=None, upsample=True, test_mode=False):\n",
        "        \"\"\" Estimate optical flow between pair of frames \"\"\"\n",
        "\n",
        "\n",
        "        image1 = image1.contiguous()\n",
        "        image2 = image2.contiguous()\n",
        "\n",
        "        hdim = self.hidden_dim\n",
        "        cdim = self.context_dim\n",
        "\n",
        "        # run the feature network\n",
        "        with autocast(enabled=self.args.mixed_precision):\n",
        "            fmap1, fmap2 = self.fnet([image1, image2])\n",
        "        fmap1 = fmap1.float()\n",
        "        fmap2 = fmap2.float()\n",
        "        corr_fn = CorrBlock(fmap1, fmap2, radius=self.args.corr_radius)\n",
        "\n",
        "        # run the context network\n",
        "        with autocast(enabled=self.args.mixed_precision):\n",
        "            cnet = self.fnet(image1)\n",
        "            net, inp = torch.split(cnet, [hdim, cdim], dim=1)\n",
        "            net = torch.tanh(net)\n",
        "            inp = torch.relu(inp)\n",
        "\n",
        "        coords0, coords1 = self.initialize_flow(image1)\n",
        "\n",
        "        if flow_init is not None:\n",
        "            coords1 = coords1 + flow_init\n",
        "\n",
        "        flow_predictions = []\n",
        "        for itr in range(iters):\n",
        "            coords1 = coords1.detach()\n",
        "            if itr == 0 and flow_init is not None:\n",
        "                coords1 = coords1 + flow_init\n",
        "            corr = corr_fn(coords1) # index correlation volume\n",
        "\n",
        "            flow = coords1 - coords0\n",
        "            with autocast(enabled=self.args.mixed_precision):\n",
        "                net, up_mask, delta_flow = self.update_block(net, inp, corr, flow)\n",
        "\n",
        "            # F(t+1) = F(t) + \\Delta(t)\n",
        "            coords1 = coords1 + delta_flow\n",
        "\n",
        "            # upsample predictions\n",
        "            if up_mask is None:\n",
        "                flow_up = upflow8(coords1 - coords0)\n",
        "            else:\n",
        "                flow_up = self.upsample_flow(coords1 - coords0, up_mask)\n",
        "\n",
        "            flow_predictions.append(flow_up)\n",
        "\n",
        "\n",
        "        return flow_predictions, flow_up, flow_init\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qwEPjsUUNEUk"
      },
      "source": [
        "#@title softsplat.py (fixing cupy)\n",
        "%%writefile /content/AnimeInterp/models/softsplat.py\n",
        "#!/usr/bin/env python\n",
        "########################\n",
        "# copy from soft splat #\n",
        "########################\n",
        "import torch\n",
        "\n",
        "import cupy\n",
        "import re\n",
        "\n",
        "kernel_Softsplat_updateOutput = '''\n",
        "\textern \"C\" __global__ void kernel_Softsplat_updateOutput(\n",
        "\t\tconst int n,\n",
        "\t\tconst float* input,\n",
        "\t\tconst float* flow,\n",
        "\t\tfloat* output\n",
        "\t) { for (int intIndex = (blockIdx.x * blockDim.x) + threadIdx.x; intIndex < n; intIndex += blockDim.x * gridDim.x) {\n",
        "\t\tconst int intN = ( intIndex / SIZE_3(output) / SIZE_2(output) / SIZE_1(output) ) % SIZE_0(output);\n",
        "\t\tconst int intC = ( intIndex / SIZE_3(output) / SIZE_2(output)                  ) % SIZE_1(output);\n",
        "\t\tconst int intY = ( intIndex / SIZE_3(output)                                   ) % SIZE_2(output);\n",
        "\t\tconst int intX = ( intIndex                                                    ) % SIZE_3(output);\n",
        "\n",
        "\t\tfloat fltOutputX = (float) (intX) + VALUE_4(flow, intN, 0, intY, intX);\n",
        "\t\tfloat fltOutputY = (float) (intY) + VALUE_4(flow, intN, 1, intY, intX);\n",
        "\n",
        "\t\tint intNorthwestX = (int) (floor(fltOutputX));\n",
        "\t\tint intNorthwestY = (int) (floor(fltOutputY));\n",
        "\t\tint intNortheastX = intNorthwestX + 1;\n",
        "\t\tint intNortheastY = intNorthwestY;\n",
        "\t\tint intSouthwestX = intNorthwestX;\n",
        "\t\tint intSouthwestY = intNorthwestY + 1;\n",
        "\t\tint intSoutheastX = intNorthwestX + 1;\n",
        "\t\tint intSoutheastY = intNorthwestY + 1;\n",
        "\n",
        "\t\tfloat fltNorthwest = ((float) (intSoutheastX) - fltOutputX   ) * ((float) (intSoutheastY) - fltOutputY   );\n",
        "\t\tfloat fltNortheast = (fltOutputX    - (float) (intSouthwestX)) * ((float) (intSouthwestY) - fltOutputY   );\n",
        "\t\tfloat fltSouthwest = ((float) (intNortheastX) - fltOutputX   ) * (fltOutputY    - (float) (intNortheastY));\n",
        "\t\tfloat fltSoutheast = (fltOutputX    - (float) (intNorthwestX)) * (fltOutputY    - (float) (intNorthwestY));\n",
        "\n",
        "\t\tif ((intNorthwestX >= 0) & (intNorthwestX < SIZE_3(output)) & (intNorthwestY >= 0) & (intNorthwestY < SIZE_2(output))) {\n",
        "\t\t\tatomicAdd(&output[OFFSET_4(output, intN, intC, intNorthwestY, intNorthwestX)], VALUE_4(input, intN, intC, intY, intX) * fltNorthwest);\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((intNortheastX >= 0) & (intNortheastX < SIZE_3(output)) & (intNortheastY >= 0) & (intNortheastY < SIZE_2(output))) {\n",
        "\t\t\tatomicAdd(&output[OFFSET_4(output, intN, intC, intNortheastY, intNortheastX)], VALUE_4(input, intN, intC, intY, intX) * fltNortheast);\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((intSouthwestX >= 0) & (intSouthwestX < SIZE_3(output)) & (intSouthwestY >= 0) & (intSouthwestY < SIZE_2(output))) {\n",
        "\t\t\tatomicAdd(&output[OFFSET_4(output, intN, intC, intSouthwestY, intSouthwestX)], VALUE_4(input, intN, intC, intY, intX) * fltSouthwest);\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((intSoutheastX >= 0) & (intSoutheastX < SIZE_3(output)) & (intSoutheastY >= 0) & (intSoutheastY < SIZE_2(output))) {\n",
        "\t\t\tatomicAdd(&output[OFFSET_4(output, intN, intC, intSoutheastY, intSoutheastX)], VALUE_4(input, intN, intC, intY, intX) * fltSoutheast);\n",
        "\t\t}\n",
        "\t} }\n",
        "'''\n",
        "\n",
        "kernel_Softsplat_updateGradInput = '''\n",
        "\textern \"C\" __global__ void kernel_Softsplat_updateGradInput(\n",
        "\t\tconst int n,\n",
        "\t\tconst float* input,\n",
        "\t\tconst float* flow,\n",
        "\t\tconst float* gradOutput,\n",
        "\t\tfloat* gradInput,\n",
        "\t\tfloat* gradFlow\n",
        "\t) { for (int intIndex = (blockIdx.x * blockDim.x) + threadIdx.x; intIndex < n; intIndex += blockDim.x * gridDim.x) {\n",
        "\t\tconst int intN = ( intIndex / SIZE_3(gradInput) / SIZE_2(gradInput) / SIZE_1(gradInput) ) % SIZE_0(gradInput);\n",
        "\t\tconst int intC = ( intIndex / SIZE_3(gradInput) / SIZE_2(gradInput)                     ) % SIZE_1(gradInput);\n",
        "\t\tconst int intY = ( intIndex / SIZE_3(gradInput)                                         ) % SIZE_2(gradInput);\n",
        "\t\tconst int intX = ( intIndex                                                             ) % SIZE_3(gradInput);\n",
        "\n",
        "\t\tfloat fltGradInput = 0.0;\n",
        "\n",
        "\t\tfloat fltOutputX = (float) (intX) + VALUE_4(flow, intN, 0, intY, intX);\n",
        "\t\tfloat fltOutputY = (float) (intY) + VALUE_4(flow, intN, 1, intY, intX);\n",
        "\n",
        "\t\tint intNorthwestX = (int) (floor(fltOutputX));\n",
        "\t\tint intNorthwestY = (int) (floor(fltOutputY));\n",
        "\t\tint intNortheastX = intNorthwestX + 1;\n",
        "\t\tint intNortheastY = intNorthwestY;\n",
        "\t\tint intSouthwestX = intNorthwestX;\n",
        "\t\tint intSouthwestY = intNorthwestY + 1;\n",
        "\t\tint intSoutheastX = intNorthwestX + 1;\n",
        "\t\tint intSoutheastY = intNorthwestY + 1;\n",
        "\n",
        "\t\tfloat fltNorthwest = ((float) (intSoutheastX) - fltOutputX   ) * ((float) (intSoutheastY) - fltOutputY   );\n",
        "\t\tfloat fltNortheast = (fltOutputX    - (float) (intSouthwestX)) * ((float) (intSouthwestY) - fltOutputY   );\n",
        "\t\tfloat fltSouthwest = ((float) (intNortheastX) - fltOutputX   ) * (fltOutputY    - (float) (intNortheastY));\n",
        "\t\tfloat fltSoutheast = (fltOutputX    - (float) (intNorthwestX)) * (fltOutputY    - (float) (intNorthwestY));\n",
        "\n",
        "\t\tif ((intNorthwestX >= 0) & (intNorthwestX < SIZE_3(gradOutput)) & (intNorthwestY >= 0) & (intNorthwestY < SIZE_2(gradOutput))) {\n",
        "\t\t\tfltGradInput += VALUE_4(gradOutput, intN, intC, intNorthwestY, intNorthwestX) * fltNorthwest;\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((intNortheastX >= 0) & (intNortheastX < SIZE_3(gradOutput)) & (intNortheastY >= 0) & (intNortheastY < SIZE_2(gradOutput))) {\n",
        "\t\t\tfltGradInput += VALUE_4(gradOutput, intN, intC, intNortheastY, intNortheastX) * fltNortheast;\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((intSouthwestX >= 0) & (intSouthwestX < SIZE_3(gradOutput)) & (intSouthwestY >= 0) & (intSouthwestY < SIZE_2(gradOutput))) {\n",
        "\t\t\tfltGradInput += VALUE_4(gradOutput, intN, intC, intSouthwestY, intSouthwestX) * fltSouthwest;\n",
        "\t\t}\n",
        "\n",
        "\t\tif ((intSoutheastX >= 0) & (intSoutheastX < SIZE_3(gradOutput)) & (intSoutheastY >= 0) & (intSoutheastY < SIZE_2(gradOutput))) {\n",
        "\t\t\tfltGradInput += VALUE_4(gradOutput, intN, intC, intSoutheastY, intSoutheastX) * fltSoutheast;\n",
        "\t\t}\n",
        "\n",
        "\t\tgradInput[intIndex] = fltGradInput;\n",
        "\t} }\n",
        "'''\n",
        "\n",
        "kernel_Softsplat_updateGradFlow = '''\n",
        "\textern \"C\" __global__ void kernel_Softsplat_updateGradFlow(\n",
        "\t\tconst int n,\n",
        "\t\tconst float* input,\n",
        "\t\tconst float* flow,\n",
        "\t\tconst float* gradOutput,\n",
        "\t\tfloat* gradInput,\n",
        "\t\tfloat* gradFlow\n",
        "\t) { for (int intIndex = (blockIdx.x * blockDim.x) + threadIdx.x; intIndex < n; intIndex += blockDim.x * gridDim.x) {\n",
        "\t\tfloat fltGradFlow = 0.0;\n",
        "\n",
        "\t\tconst int intN = ( intIndex / SIZE_3(gradFlow) / SIZE_2(gradFlow) / SIZE_1(gradFlow) ) % SIZE_0(gradFlow);\n",
        "\t\tconst int intC = ( intIndex / SIZE_3(gradFlow) / SIZE_2(gradFlow)                    ) % SIZE_1(gradFlow);\n",
        "\t\tconst int intY = ( intIndex / SIZE_3(gradFlow)                                       ) % SIZE_2(gradFlow);\n",
        "\t\tconst int intX = ( intIndex                                                          ) % SIZE_3(gradFlow);\n",
        "\n",
        "\t\tfloat fltOutputX = (float) (intX) + VALUE_4(flow, intN, 0, intY, intX);\n",
        "\t\tfloat fltOutputY = (float) (intY) + VALUE_4(flow, intN, 1, intY, intX);\n",
        "\n",
        "\t\tint intNorthwestX = (int) (floor(fltOutputX));\n",
        "\t\tint intNorthwestY = (int) (floor(fltOutputY));\n",
        "\t\tint intNortheastX = intNorthwestX + 1;\n",
        "\t\tint intNortheastY = intNorthwestY;\n",
        "\t\tint intSouthwestX = intNorthwestX;\n",
        "\t\tint intSouthwestY = intNorthwestY + 1;\n",
        "\t\tint intSoutheastX = intNorthwestX + 1;\n",
        "\t\tint intSoutheastY = intNorthwestY + 1;\n",
        "\n",
        "\t\tfloat fltNorthwest = 0.0;\n",
        "\t\tfloat fltNortheast = 0.0;\n",
        "\t\tfloat fltSouthwest = 0.0;\n",
        "\t\tfloat fltSoutheast = 0.0;\n",
        "\n",
        "\t\tif (intC == 0) {\n",
        "\t\t\tfltNorthwest = ((float) (-1.0)) * ((float) (intSoutheastY) - fltOutputY   );\n",
        "\t\t\tfltNortheast = ((float) (+1.0)) * ((float) (intSouthwestY) - fltOutputY   );\n",
        "\t\t\tfltSouthwest = ((float) (-1.0)) * (fltOutputY    - (float) (intNortheastY));\n",
        "\t\t\tfltSoutheast = ((float) (+1.0)) * (fltOutputY    - (float) (intNorthwestY));\n",
        "\n",
        "\t\t} else if (intC == 1) {\n",
        "\t\t\tfltNorthwest = ((float) (intSoutheastX) - fltOutputX   ) * ((float) (-1.0));\n",
        "\t\t\tfltNortheast = (fltOutputX    - (float) (intSouthwestX)) * ((float) (-1.0));\n",
        "\t\t\tfltSouthwest = ((float) (intNortheastX) - fltOutputX   ) * ((float) (+1.0));\n",
        "\t\t\tfltSoutheast = (fltOutputX    - (float) (intNorthwestX)) * ((float) (+1.0));\n",
        "\n",
        "\t\t}\n",
        "\n",
        "\t\tfor (int intChannel = 0; intChannel < SIZE_1(gradOutput); intChannel += 1) {\n",
        "\t\t\tfloat fltInput = VALUE_4(input, intN, intChannel, intY, intX);\n",
        "\n",
        "\t\t\tif ((intNorthwestX >= 0) & (intNorthwestX < SIZE_3(gradOutput)) & (intNorthwestY >= 0) & (intNorthwestY < SIZE_2(gradOutput))) {\n",
        "\t\t\t\tfltGradFlow += fltInput * VALUE_4(gradOutput, intN, intChannel, intNorthwestY, intNorthwestX) * fltNorthwest;\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\tif ((intNortheastX >= 0) & (intNortheastX < SIZE_3(gradOutput)) & (intNortheastY >= 0) & (intNortheastY < SIZE_2(gradOutput))) {\n",
        "\t\t\t\tfltGradFlow += fltInput * VALUE_4(gradOutput, intN, intChannel, intNortheastY, intNortheastX) * fltNortheast;\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\tif ((intSouthwestX >= 0) & (intSouthwestX < SIZE_3(gradOutput)) & (intSouthwestY >= 0) & (intSouthwestY < SIZE_2(gradOutput))) {\n",
        "\t\t\t\tfltGradFlow += fltInput * VALUE_4(gradOutput, intN, intChannel, intSouthwestY, intSouthwestX) * fltSouthwest;\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\tif ((intSoutheastX >= 0) & (intSoutheastX < SIZE_3(gradOutput)) & (intSoutheastY >= 0) & (intSoutheastY < SIZE_2(gradOutput))) {\n",
        "\t\t\t\tfltGradFlow += fltInput * VALUE_4(gradOutput, intN, intChannel, intSoutheastY, intSoutheastX) * fltSoutheast;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\n",
        "\t\tgradFlow[intIndex] = fltGradFlow;\n",
        "\t} }\n",
        "'''\n",
        "\n",
        "def cupy_kernel(strFunction, objVariables):\n",
        "\tstrKernel = globals()[strFunction]\n",
        "\n",
        "\twhile True:\n",
        "\t\tobjMatch = re.search('(SIZE_)([0-4])(\\()([^\\)]*)(\\))', strKernel)\n",
        "\n",
        "\t\tif objMatch is None:\n",
        "\t\t\tbreak\n",
        "\t\t# end\n",
        "\n",
        "\t\tintArg = int(objMatch.group(2))\n",
        "\n",
        "\t\tstrTensor = objMatch.group(4)\n",
        "\t\tintSizes = objVariables[strTensor].size()\n",
        "\n",
        "\t\tstrKernel = strKernel.replace(objMatch.group(), str(intSizes[intArg]))\n",
        "\t# end\n",
        "\n",
        "\twhile True:\n",
        "\t\tobjMatch = re.search('(OFFSET_)([0-4])(\\()([^\\)]+)(\\))', strKernel)\n",
        "\n",
        "\t\tif objMatch is None:\n",
        "\t\t\tbreak\n",
        "\t\t# end\n",
        "\n",
        "\t\tintArgs = int(objMatch.group(2))\n",
        "\t\tstrArgs = objMatch.group(4).split(',')\n",
        "\n",
        "\t\tstrTensor = strArgs[0]\n",
        "\t\tintStrides = objVariables[strTensor].stride()\n",
        "\t\tstrIndex = [ '((' + strArgs[intArg + 1].replace('{', '(').replace('}', ')').strip() + ')*' + str(intStrides[intArg]) + ')' for intArg in range(intArgs) ]\n",
        "\n",
        "\t\tstrKernel = strKernel.replace(objMatch.group(0), '(' + str.join('+', strIndex) + ')')\n",
        "\t# end\n",
        "\n",
        "\twhile True:\n",
        "\t\tobjMatch = re.search('(VALUE_)([0-4])(\\()([^\\)]+)(\\))', strKernel)\n",
        "\n",
        "\t\tif objMatch is None:\n",
        "\t\t\tbreak\n",
        "\t\t# end\n",
        "\n",
        "\t\tintArgs = int(objMatch.group(2))\n",
        "\t\tstrArgs = objMatch.group(4).split(',')\n",
        "\n",
        "\t\tstrTensor = strArgs[0]\n",
        "\t\tintStrides = objVariables[strTensor].stride()\n",
        "\t\tstrIndex = [ '((' + strArgs[intArg + 1].replace('{', '(').replace('}', ')').strip() + ')*' + str(intStrides[intArg]) + ')' for intArg in range(intArgs) ]\n",
        "\n",
        "\t\tstrKernel = strKernel.replace(objMatch.group(0), strTensor + '[' + str.join('+', strIndex) + ']')\n",
        "\t# end\n",
        "\n",
        "\treturn strKernel\n",
        "# end\n",
        "\n",
        "@cupy.memoize(for_each_device=True)\n",
        "def cupy_launch(strFunction, strKernel):\n",
        "\treturn cupy.cuda.compile_with_cache(strKernel).get_function(strFunction)\n",
        "# end\n",
        "\n",
        "class _FunctionSoftsplat(torch.autograd.Function):\n",
        "\t@staticmethod\n",
        "\tdef forward(self, input, flow):\n",
        "\t\tself.save_for_backward(input, flow)\n",
        "\n",
        "\t\tintSamples = input.shape[0]\n",
        "\t\tintInputDepth, intInputHeight, intInputWidth = input.shape[1], input.shape[2], input.shape[3]\n",
        "\t\tintFlowDepth, intFlowHeight, intFlowWidth = flow.shape[1], flow.shape[2], flow.shape[3]\n",
        "\n",
        "\t\tassert(intFlowDepth == 2)\n",
        "\t\tassert(intInputHeight == intFlowHeight)\n",
        "\t\tassert(intInputWidth == intFlowWidth)\n",
        "\n",
        "\t\tassert(input.is_contiguous() == True)\n",
        "\t\tassert(flow.is_contiguous() == True)\n",
        "\n",
        "\t\toutput = input.new_zeros([ intSamples, intInputDepth, intInputHeight, intInputWidth ])\n",
        "\n",
        "\t\tif input.is_cuda == True:\n",
        "\t\t\tn = output.nelement()\n",
        "\t\t\tcupy_launch('kernel_Softsplat_updateOutput', cupy_kernel('kernel_Softsplat_updateOutput', {\n",
        "\t\t\t\t'input': input,\n",
        "\t\t\t\t'flow': flow,\n",
        "\t\t\t\t'output': output\n",
        "\t\t\t}))(\n",
        "\t\t\t\tgrid=tuple([ int((n + 512 - 1) / 512), 1, 1 ]),\n",
        "\t\t\t\tblock=tuple([ 512, 1, 1 ]),\n",
        "\t\t\t\targs=[ n, input.data_ptr(), flow.data_ptr(), output.data_ptr() ]\n",
        "\t\t\t)\n",
        "\n",
        "\t\telif input.is_cuda == False:\n",
        "\t\t\traise NotImplementedError()\n",
        "\n",
        "\t\t# end\n",
        "\n",
        "\t\treturn output\n",
        "\t# end\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef backward(self, gradOutput):\n",
        "\t\tinput, flow = self.saved_tensors\n",
        "\n",
        "\t\tintSamples = input.shape[0]\n",
        "\t\tintInputDepth, intInputHeight, intInputWidth = input.shape[1], input.shape[2], input.shape[3]\n",
        "\t\tintFlowDepth, intFlowHeight, intFlowWidth = flow.shape[1], flow.shape[2], flow.shape[3]\n",
        "\n",
        "\t\tassert(intFlowDepth == 2)\n",
        "\t\tassert(intInputHeight == intFlowHeight)\n",
        "\t\tassert(intInputWidth == intFlowWidth)\n",
        "\n",
        "\t\t# assert(gradOutput.is_contiguous() == True)\n",
        "\n",
        "\t\tgradInput = input.new_zeros([ intSamples, intInputDepth, intInputHeight, intInputWidth ]) if self.needs_input_grad[0] == True else None\n",
        "\t\tgradFlow = input.new_zeros([ intSamples, intFlowDepth, intFlowHeight, intFlowWidth ]) if self.needs_input_grad[1] == True else None\n",
        "\n",
        "\t\tif input.is_cuda == True:\n",
        "\t\t\tif gradInput is not None:\n",
        "\t\t\t\tn = gradInput.nelement()\n",
        "\t\t\t\tcupy_launch('kernel_Softsplat_updateGradInput', cupy_kernel('kernel_Softsplat_updateGradInput', {\n",
        "\t\t\t\t\t'input': input,\n",
        "\t\t\t\t\t'flow': flow,\n",
        "\t\t\t\t\t'gradOutput': gradOutput,\n",
        "\t\t\t\t\t'gradInput': gradInput,\n",
        "\t\t\t\t\t'gradFlow': gradFlow\n",
        "\t\t\t\t}))(\n",
        "\t\t\t\t\tgrid=tuple([ int((n + 512 - 1) / 512), 1, 1 ]),\n",
        "\t\t\t\t\tblock=tuple([ 512, 1, 1 ]),\n",
        "\t\t\t\t\targs=[ n, input.data_ptr(), flow.data_ptr(), gradOutput.data_ptr(), gradInput.data_ptr(), None ]\n",
        "\t\t\t\t)\n",
        "\t\t\t# end\n",
        "\n",
        "\t\t\tif gradFlow is not None:\n",
        "\t\t\t\tn = gradFlow.nelement()\n",
        "\t\t\t\tcupy_launch('kernel_Softsplat_updateGradFlow', cupy_kernel('kernel_Softsplat_updateGradFlow', {\n",
        "\t\t\t\t\t'input': input,\n",
        "\t\t\t\t\t'flow': flow,\n",
        "\t\t\t\t\t'gradOutput': gradOutput,\n",
        "\t\t\t\t\t'gradInput': gradInput,\n",
        "\t\t\t\t\t'gradFlow': gradFlow\n",
        "\t\t\t\t}))(\n",
        "\t\t\t\t\tgrid=tuple([ int((n + 512 - 1) / 512), 1, 1 ]),\n",
        "\t\t\t\t\tblock=tuple([ 512, 1, 1 ]),\n",
        "\t\t\t\t\targs=[ n, input.data_ptr(), flow.data_ptr(), gradOutput.data_ptr(), None, gradFlow.data_ptr() ]\n",
        "\t\t\t\t)\n",
        "\t\t\t# end\n",
        "\n",
        "\t\telif input.is_cuda == False:\n",
        "\t\t\traise NotImplementedError()\n",
        "\n",
        "\t\t# end\n",
        "\n",
        "\t\treturn gradInput, gradFlow\n",
        "\t# end\n",
        "# end\n",
        "\n",
        "def FunctionSoftsplat(tenInput, tenFlow, tenMetric, strType):\n",
        "\tassert(tenMetric is None or tenMetric.shape[1] == 1)\n",
        "\tassert(strType in ['summation', 'average', 'linear', 'softmax'])\n",
        "\n",
        "\tif strType == 'average':\n",
        "\t\ttenInput = torch.cat([ tenInput, tenInput.new_ones(tenInput.shape[0], 1, tenInput.shape[2], tenInput.shape[3]) ], 1)\n",
        "\n",
        "\telif strType == 'linear':\n",
        "\t\ttenInput = torch.cat([ tenInput * tenMetric, tenMetric ], 1)\n",
        "\n",
        "\telif strType == 'softmax':\n",
        "\t\ttenInput = torch.cat([ tenInput * tenMetric.exp(), tenMetric.exp() ], 1)\n",
        "\n",
        "\t# end\n",
        "\n",
        "\ttenOutput = _FunctionSoftsplat.apply(tenInput, tenFlow)\n",
        "\n",
        "\tif strType == 'seperate':\n",
        "\t\treturn tenOutput[:, :-1, :, :], tenOutput[:, -1:, :, :] + 0.0000001\n",
        "\telif strType != 'summation':\n",
        "\t\ttenOutput = tenOutput[:, :-1, :, :] / (tenOutput[:, -1:, :, :] + 0.0000001)\n",
        "\t\n",
        "\t# end\n",
        "\n",
        "\treturn tenOutput\n",
        "# end\n",
        "\n",
        "class ModuleSoftsplat(torch.nn.Module):\n",
        "\tdef __init__(self, strType):\n",
        "\t\tsuper(ModuleSoftsplat, self).__init__()\n",
        "\n",
        "\t\tself.strType = strType\n",
        "\t# end\n",
        "\n",
        "\tdef forward(self, tenInput, tenFlow, tenMetric=None):\n",
        "\t\treturn FunctionSoftsplat(tenInput, tenFlow, tenMetric, self.strType)\n",
        "\t# end\n",
        "# end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZZ9CZsdTO5VM"
      },
      "source": [
        "#@title AnimeInterp.py (removing flow init)\n",
        "%%writefile /content/AnimeInterp/models/AnimeInterp.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "from .rfr_model.rfr_new import RFR as RFR\n",
        "from .softsplat import ModuleSoftsplat as ForwardWarp\n",
        "from .GridNet import GridNet\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    \"\"\"The quadratic model\"\"\"\n",
        "    def __init__(self, path='./network-default.pytorch'):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.prelu1 = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.prelu2 = nn.PReLU()\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
        "        self.prelu3 = nn.PReLU()\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.prelu4 = nn.PReLU()\n",
        "        self.conv5 = nn.Conv2d(64, 96, 3, stride=2, padding=1)\n",
        "        self.prelu5 = nn.PReLU()\n",
        "        self.conv6 = nn.Conv2d(96, 96, 3, padding=1)\n",
        "        self.prelu6 = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.prelu1(self.conv1(x))\n",
        "        x1 = self.prelu2(self.conv2(x))\n",
        "        x = self.prelu3(self.conv3(x1))\n",
        "        x2 = self.prelu4(self.conv4(x))\n",
        "        x = self.prelu5(self.conv5(x2))\n",
        "        x3 = self.prelu6(self.conv6(x))\n",
        "\n",
        "        return x1, x2, x3\n",
        "\n",
        "\n",
        "class AnimeInterp(nn.Module):\n",
        "    \"\"\"The quadratic model\"\"\"\n",
        "    def __init__(self, path='models/raft_model/models/rfr_sintel_latest.pth-no-zip', args=None):\n",
        "        super(AnimeInterp, self).__init__()\n",
        "\n",
        "        args = argparse.Namespace()\n",
        "        args.small = False\n",
        "        args.mixed_precision = False\n",
        "        # args.requires_sq_flow = False\n",
        "\n",
        "        self.flownet = RFR(args)\n",
        "        self.feat_ext = FeatureExtractor()\n",
        "        self.fwarp = ForwardWarp('summation')\n",
        "        self.synnet = GridNet(6, 64, 128, 96*2, 3)\n",
        "\n",
        "\n",
        "        if path is not None:\n",
        "            dict1 = torch.load(path)\n",
        "            dict2 = dict()\n",
        "            for key in dict1:\n",
        "                dict2[key[7:]] = dict1[key]\n",
        "            self.flownet.load_state_dict(dict2, strict=False)\n",
        "\n",
        "    def dflow(self, flo, target):\n",
        "        tmp = F.interpolate(flo, target.size()[2:4])\n",
        "        tmp[:, :1] = tmp[:, :1].clone() * tmp.size()[3] / flo.size()[3]\n",
        "        tmp[:, 1:] = tmp[:, 1:].clone() * tmp.size()[2] / flo.size()[2]\n",
        "\n",
        "        return tmp\n",
        "    def forward(self, I1, I2, t):\n",
        "        r = 0.6\n",
        "\n",
        "        # I1 = I1[:, [2, 1, 0]]\n",
        "        # I2 = I2[:, [2, 1, 0]]\n",
        "\n",
        "\n",
        "        # extract features\n",
        "        I1o = (I1 - 0.5) / 0.5\n",
        "        I2o = (I2 - 0.5) / 0.5\n",
        "\n",
        "        feat11, feat12, feat13 = self.feat_ext(I1o)\n",
        "        feat21, feat22, feat23 = self.feat_ext(I2o)\n",
        "\n",
        "        # calculate motion \n",
        "\n",
        "        # with torch.no_grad():\n",
        "        # self.flownet.eval()\n",
        "        F12, F12in, err12, = self.flownet(I1o, I2o, iters=12, test_mode=False, flow_init=None)\n",
        "        F21, F21in, err12, = self.flownet(I2o, I1o, iters=12, test_mode=False, flow_init=None)\n",
        "\n",
        "        F1t = t * F12\n",
        "        F2t = (1-t) * F21\n",
        "\n",
        "        F1td = self.dflow(F1t, feat11)\n",
        "        F2td = self.dflow(F2t, feat21)\n",
        "\n",
        "        F1tdd = self.dflow(F1t, feat12)\n",
        "        F2tdd = self.dflow(F2t, feat22)\n",
        "\n",
        "        F1tddd = self.dflow(F1t, feat13)\n",
        "        F2tddd = self.dflow(F2t, feat23)\n",
        "\n",
        "        # warping \n",
        "        one0 = torch.ones(I1.size(), requires_grad=True).cuda()\n",
        "        one1 = torch.ones(feat11.size(), requires_grad=True).cuda()\n",
        "        one2 = torch.ones(feat12.size(), requires_grad=True).cuda()\n",
        "        one3 = torch.ones(feat13.size(), requires_grad=True).cuda()\n",
        "\n",
        "        I1t = self.fwarp(I1, F1t)\n",
        "        feat1t1 = self.fwarp(feat11, F1td)\n",
        "        feat1t2 = self.fwarp(feat12, F1tdd)\n",
        "        feat1t3 = self.fwarp(feat13, F1tddd)\n",
        "\n",
        "        I2t = self.fwarp(I2, F2t)\n",
        "        feat2t1 = self.fwarp(feat21, F2td)\n",
        "        feat2t2 = self.fwarp(feat22, F2tdd)\n",
        "        feat2t3 = self.fwarp(feat23, F2tddd)\n",
        "\n",
        "        norm1 = self.fwarp(one0, F1t.clone())\n",
        "        norm1t1 = self.fwarp(one1, F1td.clone())\n",
        "        norm1t2 = self.fwarp(one2, F1tdd.clone())\n",
        "        norm1t3 = self.fwarp(one3, F1tddd.clone())\n",
        "\n",
        "        norm2 = self.fwarp(one0, F2t.clone())\n",
        "        norm2t1 = self.fwarp(one1, F2td.clone())\n",
        "        norm2t2 = self.fwarp(one2, F2tdd.clone())\n",
        "        norm2t3 = self.fwarp(one3, F2tddd.clone())\n",
        "\n",
        "        # normalize\n",
        "        # Note: normalize in this way benefit training than the original \"linear\"\n",
        "        I1t[norm1 > 0] = I1t.clone()[norm1 > 0] / norm1[norm1 > 0]\n",
        "        I2t[norm2 > 0] = I2t.clone()[norm2 > 0] / norm2[norm2 > 0]\n",
        "        \n",
        "        feat1t1[norm1t1 > 0] = feat1t1.clone()[norm1t1 > 0] / norm1t1[norm1t1 > 0]\n",
        "        feat2t1[norm2t1 > 0] = feat2t1.clone()[norm2t1 > 0] / norm2t1[norm2t1 > 0]\n",
        "        \n",
        "        feat1t2[norm1t2 > 0] = feat1t2.clone()[norm1t2 > 0] / norm1t2[norm1t2 > 0]\n",
        "        feat2t2[norm2t2 > 0] = feat2t2.clone()[norm2t2 > 0] / norm2t2[norm2t2 > 0]\n",
        "        \n",
        "        feat1t3[norm1t3 > 0] = feat1t3.clone()[norm1t3 > 0] / norm1t3[norm1t3 > 0]\n",
        "        feat2t3[norm2t3 > 0] = feat2t3.clone()[norm2t3 > 0] / norm2t3[norm2t3 > 0]\n",
        "\n",
        "\n",
        "        # synthesis\n",
        "        It_warp = self.synnet(torch.cat([I1t, I2t], dim=1), torch.cat([feat1t1, feat2t1], dim=1), torch.cat([feat1t2, feat2t2], dim=1), torch.cat([feat1t3, feat2t3], dim=1))\n",
        "        return It_warp, F12, F21, F12in, F21in"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgBcbIaqLwNn",
        "cellView": "form"
      },
      "source": [
        "#@title gpu inference\n",
        "%cd /content/AnimeInterp\n",
        "from types import FrameType\n",
        "from PIL import Image\n",
        "import models\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision.transforms as TF\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import warnings\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "frames_dir = \"/content/data\" #@param\n",
        "files = sorted(glob.glob(frames_dir + '/**/*.png', recursive=True))\n",
        "del files[-1]\n",
        "\n",
        "# https://github.com/lisiyao21/AnimeInterp/blob/49b1ea2ee0d6637292adbb157f0ba6b0e8cadb0d/datas/AniTriplet.py#L34\n",
        "def _pil_loader(path, cropArea=None, resizeDim=None, frameFlip=0):\n",
        "  with open(path, 'rb') as f:\n",
        "    img = Image.open(f)\n",
        "    resized_img = img.resize(resizeDim, Image.ANTIALIAS) if (resizeDim != None) else img\n",
        "    cropped_img = resized_img.crop(cropArea) if cropArea != None else resized_img\n",
        "    flipped_img = cropped_img.transpose(Image.FLIP_LEFT_RIGHT) if frameFlip else cropped_img\n",
        "    return flipped_img.convert('RGB')\n",
        "\n",
        "# https://github.com/lisiyao21/AnimeInterp/issues/8\n",
        "normalize1 = TF.Normalize([0., 0., 0.], [1.0, 1.0, 1.0])\n",
        "normalize2 = TF.Normalize([0, 0, 0], [1, 1, 1])\n",
        "trans = TF.Compose([TF.ToTensor(), normalize1, normalize2, ])\n",
        "revmean = [-x for x in [0., 0., 0.]]\n",
        "revstd = [1.0 / x for x in [1, 1, 1]]\n",
        "revnormalize1 = TF.Normalize([0.0, 0.0, 0.0], revstd)\n",
        "revnormalize2 = TF.Normalize(revmean, [1.0, 1.0, 1.0])\n",
        "revNormalize = TF.Compose([revnormalize1, revnormalize2])\n",
        "revtrans = TF.Compose([revnormalize1, revnormalize2, TF.ToPILImage()])\n",
        "to_img = TF.ToPILImage()\n",
        "\n",
        "#model = getattr(models, 'AnimeInterpNoCupy')(None).cuda()\n",
        "model = getattr(models, 'AnimeInterp')(None).cuda()\n",
        "model = nn.DataParallel(model)\n",
        "dict1 = torch.load(\"/content/anime_interp_full.ckpt\")\n",
        "model.load_state_dict(dict1['model_state_dict'], strict=False)\n",
        "model.eval()\n",
        "\n",
        "input_frame = 1\n",
        "for f in tqdm(files):\n",
        "  with torch.no_grad():\n",
        "    filename_frame_1 = f\n",
        "    filename_frame_2 = os.path.join(frames_dir, f'{input_frame+1:0>5d}.png')\n",
        "    output_frame_file_path = os.path.join(frames_dir, f\"{input_frame:0>5d}_0.5.png\")\n",
        "    frame1 = _pil_loader(filename_frame_1)\n",
        "    frame2 = _pil_loader(filename_frame_2)\n",
        "    transform1 = TF.Compose([TF.ToTensor()])\n",
        "    frame1 = transform1(frame1).unsqueeze(0)\n",
        "    frame2 = transform1(frame2).unsqueeze(0)\n",
        "    outputs = model(frame1.cuda(), frame2.cuda(), 0.5)\n",
        "    It_warp = outputs[0]\n",
        "    to_img(revNormalize(It_warp.cpu()[0]).clamp(0.0, 1.0)).save(output_frame_file_path)\n",
        "    input_frame += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FTyH0_dLJxD"
      },
      "source": [
        "# img -> video with ffmpeg\n",
        "# customize the ffmpeg command if needed\n",
        "# this is a very simple ffmpeg command, currently only creating video without sound\n",
        "%cd /content/data\n",
        "import cv2\n",
        "video = cv2.VideoCapture(\"/content/test.mkv\");\n",
        "fps = 2*video.get(cv2.CAP_PROP_FPS)\n",
        "%shell ffmpeg -y -r {fps} -f image2 -pattern_type glob -i '*.png' -crf 18 \"/content/output.mp4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4lqKnI5GMu9"
      },
      "source": [
        "# copy video back\n",
        "!cp /content/output.mp4 /content/drive/MyDrive/output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD5x4PK5MKWR"
      },
      "source": [
        "# delete output if needed\n",
        "%cd /content/\n",
        "!sudo rm -rf /content/data\n",
        "!sudo rm -rf /content/output.mp4\n",
        "!mkdir /content/data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}